{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:17:07.089421Z",
     "start_time": "2025-07-13T23:17:07.050522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "directory = \"/Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcripted_episodes/episodes_with_timestamps/new_episodes\"\n",
    "saf_root = \"SAF/\"\n",
    "\n",
    "def create_SAF_Folder(episode_number:int):\n",
    "    # Create the folder\n",
    "    episode_folder_path = saf_root + str(episode_number)\n",
    "    print(episode_folder_path)\n",
    "    os.makedirs(episode_folder_path, exist_ok=True)\n",
    "\n",
    "    # Connect to cursor to retreive all important information.\n",
    "    with sqlite3.connect(\"nasil_olunur_database.db\") as connection:\n",
    "        cursor = connection.cursor()\n",
    "        query = \"\"\"SELECT title,episode_date,audio_url,word_document_name,description_tr,description_en\n",
    "                    FROM episodes WHERE episode_number = ?\"\"\"\n",
    "        cursor.execute(query, (episode_number,))\n",
    "        episode = cursor.fetchone()\n",
    "        title,episode_date,audio_url,word_document_name,description_tr,description_en = episode\n",
    "\n",
    "        # Need to retrieve guest information\n",
    "        guest_query = \"\"\" SELECT guest_name FROM guests WHERE episode_number = ?\"\"\"\n",
    "        cursor.execute(guest_query, (episode_number,))\n",
    "        guests = cursor.fetchall()\n",
    "        guests = ' - '.join(name[0] for name in guests) # it's a string now.\n",
    "\n",
    "        # Need to retrieve subject keywords.\n",
    "        keyword_query = \"\"\"SELECT type, keyword_text FROM keywords WHERE episode_number = ?\"\"\"\n",
    "        cursor.execute(keyword_query, (episode_number,))\n",
    "        keywords = cursor.fetchall()\n",
    "        kw_dict = defaultdict(list) # key = keyword type, val = keyword text\n",
    "        for label, kw in keywords:\n",
    "            kw_dict[label].append(kw)\n",
    "\n",
    "    # Add the .txt file\n",
    "    add_txt(episode_folder_path, word_document_name)\n",
    "\n",
    "    # Create the contents file\n",
    "    create_contents(episode_folder_path)\n",
    "\n",
    "    # Create the dublin_core\n",
    "    # create_dublin_core(episode_number, episode_folder_path)\n",
    "    create_dublin_core(guests,\n",
    "                       episode_date,\n",
    "                       description_tr,\n",
    "                       description_en,\n",
    "                       title,\n",
    "                       audio_url,\n",
    "                       kw_dict[\"subject_tr\"],\n",
    "                       kw_dict[\"subject_en\"],\n",
    "                       episode_number,\n",
    "                       episode_folder_path)\n",
    "\n",
    "    # Create the metadata file\n",
    "    create_metadata(episode_number,\n",
    "                    episode_folder_path,\n",
    "                    kw_dict[\"person\"],\n",
    "                    kw_dict[\"place_tr\"])\n",
    "\n",
    "# create_SAF_Folder(235)"
   ],
   "id": "49a21f7db3176c3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAF/235\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:18:28.429584Z",
     "start_time": "2025-07-13T23:18:28.224596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch Create SAF FOLDERS\n",
    "def batch_create_SAF(start_ep:int, end_ep:int):\n",
    "\n",
    "    for i in range(start_ep, end_ep+1):\n",
    "        try:\n",
    "            create_SAF_Folder(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error when creating saf folder {i}. --> {e}\")\n",
    "    remove_ds_store()\n",
    "    zip_folders(start_ep,end_ep+1)\n",
    "\n",
    "# batch_create_SAF(235,243)"
   ],
   "id": "91325ae7231f39ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAF/235\n",
      "SAF/236\n",
      "SAF/237\n",
      "SAF/238\n",
      "SAF/239\n",
      "SAF/240\n",
      "SAF/241\n",
      "SAF/242\n",
      "SAF/243\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'zip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 14\u001B[0m\n\u001B[1;32m     10\u001B[0m     zip_folders(start_ep,end_ep\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# batch_create_SAF(65,65)\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# batch_create_SAF(159,234)\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[43mbatch_create_SAF\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m235\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m243\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[42], line 10\u001B[0m, in \u001B[0;36mbatch_create_SAF\u001B[0;34m(start_ep, end_ep)\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError when creating saf folder \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. --> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m remove_ds_store()\n\u001B[0;32m---> 10\u001B[0m \u001B[43mzip_folders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_ep\u001B[49m\u001B[43m,\u001B[49m\u001B[43mend_ep\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[14], line 12\u001B[0m, in \u001B[0;36mzip_folders\u001B[0;34m(start_ep, end_ep)\u001B[0m\n\u001B[1;32m      9\u001B[0m item_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory,item)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m#Check if the item is a folder\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(item_path) \u001B[38;5;129;01mand\u001B[39;00m (start_ep \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m end_ep):\n\u001B[1;32m     13\u001B[0m     zip_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(zip_directory,item)\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'zip'"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:21:27.040766Z",
     "start_time": "2025-07-13T23:21:26.984131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def zip_folders(start_ep:int, end_ep:int):\n",
    "    directory = \"/Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF\"\n",
    "    zip_directory = directory + \"/zip\"\n",
    "\n",
    "    for item in os.listdir(directory):\n",
    "        print(\"item is: \", item)\n",
    "        item_path = os.path.join(directory,item)\n",
    "\n",
    "        #Check if the item is a folder\n",
    "        if os.path.isdir(item_path) and (start_ep <= int(item) <= end_ep):\n",
    "            zip_path = os.path.join(zip_directory,item)\n",
    "            try:\n",
    "                shutil.make_archive(zip_path, 'zip', item_path)\n",
    "                print(f\"Zipped: {item_path} -> {zip_path}.zip\")\n",
    "            except Exception as e:\n",
    "                print(f\"Problem zipping {item_path}. Error -> {e}\")\n",
    "\n",
    "# zip_folders(235,243)"
   ],
   "id": "6895739a99f596e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item is:  .DS_Store\n",
      "item is:  242\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/242 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/242.zip\n",
      "item is:  243\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/243 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/243.zip\n",
      "item is:  235\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/235 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/235.zip\n",
      "item is:  241\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/241 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/241.zip\n",
      "item is:  240\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/240 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/240.zip\n",
      "item is:  236\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/236 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/236.zip\n",
      "item is:  238\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/238 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/238.zip\n",
      "item is:  239\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/239 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/239.zip\n",
      "item is:  237\n",
      "Zipped: /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/237 -> /Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcription_notebooks/SAF/zip/237.zip\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:00:25.244873Z",
     "start_time": "2025-07-13T23:00:25.241172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def remove_ds_store(): # Removes the macOS specific .DS_Store files\n",
    "    directory = \"/Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/SAF\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \".DS_Store\":\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "# remove_ds_store()"
   ],
   "id": "7814759ed73d1f41",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:00:26.055905Z",
     "start_time": "2025-07-13T23:00:26.052737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Keyword querying trial\n",
    "def deneme_keyword_retrieval():\n",
    "    from collections import defaultdict\n",
    "    episode_number = 61\n",
    "    with sqlite3.connect(\"nasil_olunur_database.db\") as connection:\n",
    "        cursor = connection.cursor()\n",
    "        keyword_query = \"\"\"\n",
    "            SELECT type, keyword_text FROM keywords WHERE episode_number = ?\n",
    "        \"\"\"\n",
    "        cursor.execute(keyword_query, (episode_number,))\n",
    "        keywords = cursor.fetchall()\n",
    "\n",
    "        kw_dict = defaultdict(list)\n",
    "        for label, kw in keywords:\n",
    "            kw_dict[label].append(kw)\n",
    "            # print(f\"Label-> {label}, keyword-> {kw}\")\n",
    "\n",
    "        print(kw_dict.keys())"
   ],
   "id": "4294e5cecac942a6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:00:26.584923Z",
     "start_time": "2025-07-13T23:00:26.574779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    Function to create dublin_core file\n",
    "\"\"\"\n",
    "\n",
    "def create_dublin_core(guests,episode_date, description_tr, description_en, title, audio_url, subject_tr, subject_en, episode_number, episode_folder_path):\n",
    "\n",
    "    #Clearing audio_url\n",
    "    audio_url = audio_url[:audio_url.find(\"mp3\")+3]\n",
    "\n",
    "    dublin_core_metadata_structure = {\n",
    "        \"contributor_author\": guests,\n",
    "        \"date_accessioned\": str(date.today()),\n",
    "        \"date_issued\": str(episode_date), # tire (-) ile ayirmam gerekir mi?\n",
    "        \"episode_no\": str(episode_number),\n",
    "        \"identifier_uri\": audio_url,\n",
    "        \"description_abstract_en\": description_en,\n",
    "        \"description_abstract_tr\": description_tr,\n",
    "        \"language_iso\": \"tr\",\n",
    "        \"subjects\": {\n",
    "            \"en\": subject_en,\n",
    "            \"tr\": subject_tr,\n",
    "        },\n",
    "        \"title\": title,\n",
    "        \"type\": \"Recording, oral\",\n",
    "    }\n",
    "\n",
    "    # Create the root element\n",
    "    root = ET.Element(\"dublin_core\", attrib={\"schema\": \"dc\"})\n",
    "\n",
    "    # Add metadata as sub-elements\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"contributor\", \"qualifier\": \"author\"}).text = dublin_core_metadata_structure[\"contributor_author\"]\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"date\", \"qualifier\": \"accessioned\"}).text = dublin_core_metadata_structure[\"date_accessioned\"]\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"date\", \"qualifier\": \"issued\"}).text = dublin_core_metadata_structure[\"date_issued\"]\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"identifier\", \"qualifier\": \"none\"}).text = dublin_core_metadata_structure[\"episode_no\"]\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"identifier\", \"qualifier\": \"uri\"}).text = dublin_core_metadata_structure[\"identifier_uri\"]\n",
    "\n",
    "    # Add descriptions\n",
    "    ET.SubElement(\n",
    "        root,\n",
    "        \"dcvalue\",\n",
    "        attrib={\"element\": \"description\", \"qualifier\": \"version\"}\n",
    "    ).text = dublin_core_metadata_structure[\"description_abstract_en\"]\n",
    "    ET.SubElement(\n",
    "        root,\n",
    "        \"dcvalue\",\n",
    "        attrib={\"element\": \"description\", \"qualifier\": \"abstract\"}\n",
    "    ).text = dublin_core_metadata_structure[\"description_abstract_tr\"]\n",
    "\n",
    "    # Add Language attribute\n",
    "    ET.SubElement(\n",
    "        root,\n",
    "        \"dcvalue\",\n",
    "        attrib={\"element\": \"language\", \"qualifier\": \"iso\"}\n",
    "    ).text = \"tr\"\n",
    "\n",
    "    # Add subjects\n",
    "    for subject in dublin_core_metadata_structure[\"subjects\"][\"en\"]:\n",
    "        ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"subject\", \"qualifier\": \"none\"}).text = subject\n",
    "\n",
    "    for subject in dublin_core_metadata_structure[\"subjects\"][\"tr\"]:\n",
    "        ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"subject\", \"qualifier\": \"none\"}).text = subject\n",
    "\n",
    "    # Add title and type\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"title\", \"qualifier\": \"none\"}).text = dublin_core_metadata_structure[\"title\"]\n",
    "    ET.SubElement(root, \"dcvalue\", attrib={\"element\": \"type\", \"qualifier\": \"none\"}).text = dublin_core_metadata_structure[\"type\"]\n",
    "\n",
    "    # Write to an XML file\n",
    "    output_file = os.path.join(episode_folder_path, \"dublin_core.xml\")\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(output_file, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    # print(f\"XML file created: {output_file}\")"
   ],
   "id": "f6c574193d51c851",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:00:27.107693Z",
     "start_time": "2025-07-13T23:00:27.104303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_contents(path):\n",
    "    text = \"\"\n",
    "    for item in os.listdir(path):\n",
    "        if item != \".DS_Store\":\n",
    "            text += item + \"\\n\"\n",
    "\n",
    "    # save it into a file in correct dir.\n",
    "    with open(path+\"/contents\", \"w\") as f:\n",
    "        f.write(text)\n",
    "# create_contents(\"/Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/SAF/61\")\n"
   ],
   "id": "27b852a5c7f2efc0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:17:02.560380Z",
     "start_time": "2025-07-13T23:17:02.556246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from docx import Document\n",
    "\n",
    "def add_txt(episode_folder_path, word_document_name):\n",
    "    doc = Document(word_document_name)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "    n_start = word_document_name.find(\"new_episodes/\") + 13\n",
    "    name = word_document_name[n_start:-5]+\".txt\".strip()\n",
    "\n",
    "    with open(f\"{episode_folder_path}/{name}\", \"w\") as file:\n",
    "        file.write(text)\n"
   ],
   "id": "ce2b997a00dbfe38",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:16:56.185742Z",
     "start_time": "2025-07-13T23:16:56.178407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def add_word_addresses():\n",
    "    with sqlite3.connect(\"nasil_olunur_database.db\") as connection:\n",
    "        data = []\n",
    "        directory = \"/Users/kaanerdem/Desktop/projeler/pdtxt/pdtxt_notebook/transcripted_episodes/episodes_with_timestamps/new_episodes\"\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".docx\"):\n",
    "                ep_no = int(filename[:filename.find(\"-\")].strip())\n",
    "                full_ad = os.path.join(directory, filename)\n",
    "                data.append((full_ad,ep_no))\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        query = \"\"\"\n",
    "            UPDATE episodes\n",
    "            SET word_document_name = ?\n",
    "            WHERE episode_number = ?\n",
    "        \"\"\"\n",
    "        cursor.executemany(query,data)\n",
    "\n",
    "add_word_addresses()"
   ],
   "id": "47640b603b86c17d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T23:16:58.844338Z",
     "start_time": "2025-07-13T23:16:58.839799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_metadata(episode_number,episode_folder_path, person, place_tr):\n",
    "\n",
    "    # Create the root element\n",
    "    root = ET.Element(\"dublin_core\", schema=\"local\")\n",
    "\n",
    "    # Add people to the XML\n",
    "    for p in person:\n",
    "        dcvalue = ET.SubElement(root, \"dcvalue\")\n",
    "        dcvalue.set(\"element\", \"person\")\n",
    "        dcvalue.set(\"qualifier\", \"name\")\n",
    "        dcvalue.text = p\n",
    "\n",
    "    # Add places to the XML\n",
    "    for place in place_tr:\n",
    "        dcvalue = ET.SubElement(root, \"dcvalue\")\n",
    "        dcvalue.set(\"element\", \"place\")\n",
    "        dcvalue.set(\"qualifier\", \"name\")\n",
    "        dcvalue.text = place\n",
    "\n",
    "    # Create an ElementTree object\n",
    "    tree = ET.ElementTree(root)\n",
    "\n",
    "    output_dir = episode_folder_path\n",
    "    output_file = os.path.join(output_dir, \"metadata_local.xml\")\n",
    "    # Write the tree to an XML file\n",
    "    with open(output_file, \"wb\") as file:\n",
    "        file.write(b'<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\\n')\n",
    "        tree.write(file, encoding=\"utf-8\", xml_declaration=False)"
   ],
   "id": "938297671ab7b93c",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb263d5b2add7e29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
